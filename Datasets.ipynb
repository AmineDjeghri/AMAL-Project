{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_dataset_name(mode):\n",
    "    if mode == \"ade20k\":\n",
    "        return \"Ade20kDataset\"\n",
    "    if mode == \"cityscapes\":\n",
    "        return \"CityscapesDataset\"\n",
    "    if mode == \"coco\":\n",
    "        return \"CocoStuffDataset\"\n",
    "    else:\n",
    "        ValueError(\"There is no such dataset regime as %s\" % mode)\n",
    "\n",
    "\n",
    "def get_dataloaders(opt):\n",
    "    dataset_name   = get_dataset_name(opt.dataset_mode)\n",
    "\n",
    "    file = __import__(\"dataloaders.\"+dataset_name)\n",
    "    dataset_train = file.__dict__[dataset_name].__dict__[dataset_name](opt, for_metrics=False)\n",
    "    dataset_val   = file.__dict__[dataset_name].__dict__[dataset_name](opt, for_metrics=True)\n",
    "    print(\"Created %s, size train: %d, size val: %d\" % (dataset_name, len(dataset_train), len(dataset_val)))\n",
    "\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = opt.batch_size, shuffle = True, drop_last=True)\n",
    "    dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size = opt.batch_size, shuffle = False, drop_last=False)\n",
    "\n",
    "    return dataloader_train, dataloader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torchvision import transforms as TR\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Ade20kDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt, for_metrics):\n",
    "        if opt.phase == \"test\" or for_metrics:\n",
    "            opt.load_size = 256\n",
    "        else:\n",
    "            opt.load_size = 286\n",
    "        opt.crop_size = 256\n",
    "        opt.label_nc = 150\n",
    "        opt.contain_dontcare_label = True\n",
    "        opt.semantic_nc = 151 # label_nc + unknown\n",
    "        opt.cache_filelist_read = False\n",
    "        opt.cache_filelist_write = False\n",
    "        opt.aspect_ratio = 1.0\n",
    "\n",
    "        self.opt = opt\n",
    "        self.for_metrics = for_metrics\n",
    "        self.images, self.labels, self.paths = self.list_images()\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.paths[0], self.images[idx])).convert('RGB')\n",
    "        label = Image.open(os.path.join(self.paths[1], self.labels[idx]))\n",
    "        image, label = self.transforms(image, label)\n",
    "        label = label * 255\n",
    "        return {\"image\": image, \"label\": label, \"name\": self.images[idx]}\n",
    "\n",
    "    def list_images(self):\n",
    "        mode = \"validation\" if self.opt.phase == \"test\" or self.for_metrics else \"training\"\n",
    "        path_img = os.path.join(self.opt.dataroot, \"images\", mode)\n",
    "        path_lab = os.path.join(self.opt.dataroot, \"annotations\", mode)\n",
    "        img_list = os.listdir(path_img)\n",
    "        lab_list = os.listdir(path_lab)\n",
    "        img_list = [filename for filename in img_list if \".png\" in filename or \".jpg\" in filename]\n",
    "        lab_list = [filename for filename in lab_list if \".png\" in filename or \".jpg\" in filename]\n",
    "        images = sorted(img_list)\n",
    "        labels = sorted(lab_list)\n",
    "        assert len(images)  == len(labels), \"different len of images and labels %s - %s\" % (len(images), len(labels))\n",
    "        for i in range(len(images)):\n",
    "            assert os.path.splitext(images[i])[0] == os.path.splitext(labels[i])[0], '%s and %s are not matching' % (images[i], labels[i])\n",
    "        return images, labels, (path_img, path_lab)\n",
    "\n",
    "    def transforms(self, image, label):\n",
    "        assert image.size == label.size\n",
    "        # resize\n",
    "        new_width, new_height = (self.opt.load_size, self.opt.load_size)\n",
    "        image = TR.functional.resize(image, (new_width, new_height), Image.BICUBIC)\n",
    "        label = TR.functional.resize(label, (new_width, new_height), Image.NEAREST)\n",
    "        # crop\n",
    "        crop_x = random.randint(0, np.maximum(0, new_width -  self.opt.crop_size))\n",
    "        crop_y = random.randint(0, np.maximum(0, new_height - self.opt.crop_size))\n",
    "        image = image.crop((crop_x, crop_y, crop_x + self.opt.crop_size, crop_y + self.opt.crop_size))\n",
    "        label = label.crop((crop_x, crop_y, crop_x + self.opt.crop_size, crop_y + self.opt.crop_size))\n",
    "        # flip\n",
    "        if not (self.opt.phase == \"test\" or self.opt.no_flip or self.for_metrics):\n",
    "            if random.random() < 0.5:\n",
    "                image = TR.functional.hflip(image)\n",
    "                label = TR.functional.hflip(label)\n",
    "        # to tensor\n",
    "        image = TR.functional.to_tensor(image)\n",
    "        label = TR.functional.to_tensor(label)\n",
    "        # normalize\n",
    "        image = TR.functional.normalize(image, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
